% simple document template
\documentclass{paper}
\usepackage{tikz}
\usetikzlibrary{graphs}
\usetikzlibrary {mindmap}
\usetikzlibrary {positioning}
\usetikzlibrary {arrows.meta}
\usetikzlibrary {shapes.multipart}
\usetikzlibrary {shapes.geometric}
\usetikzlibrary {shapes.symbols}
\usetikzlibrary {shapes.callouts}
\usetikzlibrary {calc}
\begin{document}

% #ff9393	(255,147,147)
% #fdbcb4	(253,188,180)
% #ffefd5	(255,239,213)
% #b9d9eb	(185,217,235)
% #85b2b0	(133,178,176)

% ==========[Section 2022 TODO]===========
\section{2022 TODO}
\subsection{List of modules}
\begin{enumerate}
\item \textbf{1. Numerical accuracy}
\item \textbf{2. Reproducibility}
\item \textbf{3. torch script}
\item \textbf{4. torch.utils.tensorboard}
\item \textbf{5. torch.nn.functional}
\item \textbf{6. torch.func }
\item \textbf{7. torch.special}
\item \textbf{8. CUDA Automatic Mixed Precision examples}
\item \textbf{9. Extending PyTorch}
\item \textbf{10. Distributed Checkpoint - torch.distributed.checkpoint¶}
\item \textbf{11. torch.optim}
\item \textbf{12. torch Custom Backends}
\item \textbf{13. Tensor Parallelism - torch.distributed.tensor.parallel}
\item \textbf{14. torch.profiler¶}
\item \textbf{15. Quantization}
\item \textbf{16. Autograd mechanics}
\item \textbf{17. Probability distributions - torch.distributions}
\item \textbf{18. TorchDynamo Troubleshooting}
\item \textbf{19. torch.backends}
\item \textbf{20. Gradcheck mechanics }
\item \textbf{21. Benchmark Utils - torch.utils.benchmark — PyTorch 2.0 documentation}
\item \textbf{22. torch Expressions}
\item \textbf{https://www.youtube.com/watch?v=8-nhHgH8498}
\end{enumerate}

\end{document}